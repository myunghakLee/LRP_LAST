{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "131861b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T11:04:32.173892Z",
     "start_time": "2022-03-13T11:04:32.171120Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "83398e83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T11:04:32.352326Z",
     "start_time": "2022-03-13T11:04:32.347982Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from glob import glob\n",
    "import torchvision\n",
    "import datetime\n",
    "import numpy\n",
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6dbbf0b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T11:04:32.590643Z",
     "start_time": "2022-03-13T11:04:32.588159Z"
    }
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8fa407de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T11:04:33.192927Z",
     "start_time": "2022-03-13T11:04:33.188275Z"
    }
   },
   "outputs": [],
   "source": [
    "class Cifar100(Dataset):\n",
    "    def __init__(self, data_dir, transform = None):\n",
    "        self.transform = transform\n",
    "        self.train_data = []\n",
    "        self.train_files = glob(data_dir + \"/*.pickle\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_files)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        with open(self.train_files[idx], 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        return data['img'], data['softlabel'], data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "efad7ea6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T11:04:33.763072Z",
     "start_time": "2022-03-13T11:04:33.728093Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = \"LRP_data_resnext101_32x8d_0_8514/test/\"\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(settings.CIFAR100_TRAIN_MEAN, settings.CIFAR100_TRAIN_STD)\n",
    "])\n",
    "\n",
    "\n",
    "cifar100_test = Cifar100(transform=transform_test, data_dir = data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "24286b08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T11:04:35.113335Z",
     "start_time": "2022-03-13T11:04:34.418059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(settings.CIFAR100_TRAIN_MEAN, settings.CIFAR100_TRAIN_STD)\n",
    "])\n",
    "#cifar100_test = CIFAR100Test(path, transform=transform_test)\n",
    "cifar100_test2 = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "82c5c06f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T11:12:11.715124Z",
     "start_time": "2022-03-13T11:12:11.711058Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9d4de4ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T12:26:38.472919Z",
     "start_time": "2022-03-13T12:26:37.294149Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg11(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2736746e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T12:28:06.024450Z",
     "start_time": "2022-03-13T12:27:57.219270Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8453556b974b7ca4e2c13e6c0e9737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg19(pretrained=True)\n",
    "model.classifier[6]= nn.Linear(4096, 100)\n",
    "img = torch.randn(1,3,224,224)\n",
    "model(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b67a3f9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T12:25:50.201720Z",
     "start_time": "2022-03-13T12:25:50.195650Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torchvision.models.vgg.vgg13(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.vgg13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731bd45a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
